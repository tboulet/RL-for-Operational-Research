name: Q-Learning
config:
  
  # ============== Hyperparameters ==============
  # The learning rate
  learning_rate: 0.1

  # The discount factor
  gamma : 0.99

  # ============== Q Values Model ==============
  q_model:
    class_string: "src.learners.tabular:QValuesTabularLearner"
    method_q_value_initialization : random
    typical_return : 1.0
    typical_return_std : 1.0

  # ============== Exploration ==============
  # The method for the exploratory policy. Either "eps_greedy", "boltzmann", "ucb",
  method_exploration : boltzmann

  # The UCB constant (if method_exploration is UCB)
  ucb_constant : 2.0

  # The boltzmann temperature (if method_exploration is boltzmann)
  boltzmann_temperature:
    class_string : "src.schedulers:Exponential"
    start_value : 10.0
    end_value : 0.01
    n_steps : ${n_steps_exploration}

  # The epsilon parameter (if method_exploration is eps_greedy)
  # epsilon : 0.1
  epsilon:
    class_string : "src.schedulers:Exponential"
    start_value : 1.0
    end_value : 0.05
    n_steps : ${n_steps_exploration}
    lower_bound : 0.05
  
  # epsilon:
  #   class_string : "src.schedulers:Inverse"
  #   value_start : 1.0
  #   value_target : 0.0
  #   value_n_steps : 0.2
  #   n_steps : ${n_steps_exploration}
  #   lower_bound : 0.05

  # ============== Logging ==============
  do_log_q_values : False
  n_max_q_values_states_to_log : 1
  do_log_actions_chosen : False
